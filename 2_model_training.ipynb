{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37c69ad",
      "metadata": {
        "collapsed": true,
        "id": "d37c69ad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dropout, LayerNormalization, Dense, Lambda\n",
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"./data\"\n",
        "model_path = \"./model\""
      ],
      "metadata": {
        "id": "a3XUr8aBhML8"
      },
      "id": "a3XUr8aBhML8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicTokenizer:\n",
        "    def __init__(self):\n",
        "        self.token_to_id = {}\n",
        "        self.id_to_token = {}\n",
        "\n",
        "    def build_vocab(self, sequences):\n",
        "        for line in sequences:\n",
        "            parts = line.strip().split()\n",
        "            for token in parts:\n",
        "                if token not in self.token_to_id:\n",
        "                    token_id = len(self.token_to_id)\n",
        "                    self.token_to_id[token] = token_id\n",
        "                    self.id_to_token[token_id] = token\n",
        "\n",
        "    def encode(self, sequences):\n",
        "        return [[self.token_to_id[token] for token in line.strip().split()] for line in sequences]\n",
        "\n",
        "    def decode(self, id_sequences):\n",
        "        return [\" \".join([self.id_to_token[token_id] for token_id in line]) for line in id_sequences]\n",
        "\n",
        "    def decode2(self, id_sequences):\n",
        "        return [\" \".join([self.id_to_token[id] for id in id_sequences])]"
      ],
      "metadata": {
        "id": "6uhmVbp6iBS8"
      },
      "id": "6uhmVbp6iBS8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234b7202",
      "metadata": {
        "id": "234b7202"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbeddingAdder(tf.keras.layers.Layer):\n",
        "    def __init__(self, max_seq_length, d_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.d_model = d_model\n",
        "        self.position_embeddings = Embedding(max_seq_length, d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
        "        pos_embeds = self.position_embeddings(positions)\n",
        "        return x + pos_embeds\n",
        "\n",
        "class LastToken(tf.keras.layers.Layer):\n",
        "    def call(self, x):\n",
        "        return x[:, -1, :]\n",
        "\n",
        "# Transformer model definition\n",
        "def transformer_model(input_vocab_size, output_vocab_size, max_seq_length, d_model=128, num_heads=4, num_layers=2, dropout_rate=0.25):\n",
        "    inputs = Input(shape=(max_seq_length,), dtype=tf.int32)\n",
        "\n",
        "    # Token embedding\n",
        "    token_embedding = Embedding(input_vocab_size, d_model)(inputs)\n",
        "\n",
        "    # Add positional embedding\n",
        "    outputs = PositionalEmbeddingAdder(max_seq_length, d_model)(token_embedding)\n",
        "\n",
        "    # Transformer blocks\n",
        "    for _ in range(num_layers):\n",
        "        attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(\n",
        "            outputs, outputs,\n",
        "            attention_mask=tf.linalg.band_part(tf.ones((max_seq_length, max_seq_length)), -1, 0)\n",
        "        )\n",
        "        attention_output = Dropout(dropout_rate)(attention_output)\n",
        "        attention_output = LayerNormalization(epsilon=1e-7)(outputs + attention_output)\n",
        "\n",
        "        ffn_output = Dense(d_model * 4, activation='gelu')(attention_output)\n",
        "        ffn_output = Dense(d_model, activation='gelu')(ffn_output)\n",
        "        ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "\n",
        "        outputs = LayerNormalization(epsilon=1e-7)(attention_output + ffn_output)\n",
        "\n",
        "    # Only keep the last token's output to predict the next token\n",
        "    outputs = LastToken()(outputs)\n",
        "\n",
        "    # Final prediction layer\n",
        "    outputs = Dense(output_vocab_size, activation='softmax')(outputs)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b533b3",
      "metadata": {
        "id": "74b533b3"
      },
      "outputs": [],
      "source": [
        "x_train = np.load(f'{data_path}/x_train.npy')\n",
        "x_test = np.load(f'{data_path}/x_test.npy')\n",
        "x_val = np.load(f'{data_path}/x_val.npy')\n",
        "y_train = np.load(f'{data_path}/y_train.npy')\n",
        "y_test = np.load(f'{data_path}/y_test.npy')\n",
        "y_val = np.load(f'{data_path}/y_val.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1fc957",
      "metadata": {
        "id": "5f1fc957"
      },
      "outputs": [],
      "source": [
        "with open(f\"{model_path}/tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "382f1c6e",
      "metadata": {
        "id": "382f1c6e"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "vocab_size = len(tokenizer.token_to_id)\n",
        "max_seq_length = len(x_train[0])\n",
        "\n",
        "model = transformer_model(\n",
        "    input_vocab_size=vocab_size,\n",
        "    output_vocab_size=vocab_size,\n",
        "    max_seq_length=max_seq_length,\n",
        "    d_model=256,\n",
        "    num_heads=8,\n",
        "    num_layers=4\n",
        ")\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b552b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b552b0",
        "outputId": "1867f6fd-6e3c-4e81-a345-87035553a411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m948s\u001b[0m 52ms/step - accuracy: 0.6154 - loss: 1.4129 - val_accuracy: 0.7121 - val_loss: 0.9864\n",
            "Epoch 2/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 51ms/step - accuracy: 0.7226 - loss: 0.9459 - val_accuracy: 0.7473 - val_loss: 0.8679\n",
            "Epoch 3/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 50ms/step - accuracy: 0.7498 - loss: 0.8482 - val_accuracy: 0.7620 - val_loss: 0.8088\n",
            "Epoch 4/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m886s\u001b[0m 50ms/step - accuracy: 0.7657 - loss: 0.7908 - val_accuracy: 0.7709 - val_loss: 0.7909\n",
            "Epoch 5/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m881s\u001b[0m 50ms/step - accuracy: 0.7781 - loss: 0.7465 - val_accuracy: 0.7807 - val_loss: 0.7575\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a14105da910>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb216a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eb216a9",
        "outputId": "db8f1b28-b2a6-48ff-9c28-ad80c63d950d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2207/2207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.7827 - loss: 0.7613\n",
            "Test Accuracy: 0.7816\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec07bb44",
      "metadata": {
        "id": "ec07bb44"
      },
      "outputs": [],
      "source": [
        "model.save(f\"{model_path}/model_5epochs.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58647776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58647776",
        "outputId": "ec2ad789-9d96-449a-d826-db3cbc64ddb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m881s\u001b[0m 50ms/step - accuracy: 0.7888 - loss: 0.7112 - val_accuracy: 0.7868 - val_loss: 0.7378\n",
            "Epoch 2/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 50ms/step - accuracy: 0.7973 - loss: 0.6803 - val_accuracy: 0.7925 - val_loss: 0.7292\n",
            "Epoch 3/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m896s\u001b[0m 51ms/step - accuracy: 0.8056 - loss: 0.6502 - val_accuracy: 0.8004 - val_loss: 0.7052\n",
            "Epoch 4/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m898s\u001b[0m 51ms/step - accuracy: 0.8147 - loss: 0.6220 - val_accuracy: 0.8039 - val_loss: 0.6871\n",
            "Epoch 5/5\n",
            "\u001b[1m17650/17650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m904s\u001b[0m 51ms/step - accuracy: 0.8215 - loss: 0.5964 - val_accuracy: 0.8091 - val_loss: 0.6779\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a12dc50af10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea465909",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea465909",
        "outputId": "bf131786-0206-4132-f1ea-0b7d182a9ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2207/2207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8087 - loss: 0.6782\n",
            "Test Accuracy: 0.8089\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc12468d",
      "metadata": {
        "id": "cc12468d"
      },
      "outputs": [],
      "source": [
        "model.save(f\"{model_path}/model_10epochs.keras\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}